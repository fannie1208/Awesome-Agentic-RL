<a name="readme-top"></a>


<div align="center">

<a href="https://github.com/fannie1208/Awesome-Agentic-RL"><img src="https://img.shields.io/github/last-commit/fannie1208/Awesome-Agentic-RL?style=for-the-badge" alt="Last Commit"></a>
<a href="https://github.com/fannie1208/Awesome-Agentic-RL/stargazers"><img src="https://img.shields.io/github/stars/fannie1208/Awesome-Agentic-RL?style=for-the-badge" alt="Stargazers"></a>
<a href="https://github.com/fannie1208/Awesome-Agentic-RL/network/members"><img src="https://img.shields.io/github/forks/fannie1208/Awesome-Agentic-RL?style=for-the-badge" alt="Forks"></a>
<a href="https://github.com/fannie1208/Awesome-Agentic-RL/blob/main/LICENSE"><img src="https://img.shields.io/github/license/fannie1208/Awesome-Agentic-RL?style=for-the-badge" alt="MIT License"></a>
<img src="https://img.shields.io/badge/Contributions-welcome-red?style=for-the-badge" alt="Contribution Welcome">

</div>


<h1 align="center">Awesome Agentic RL</h1>

<p align="center">
    <b> Collection of papers and resources on training LLM agents with RL.</b>
</p>


<!-- Table of Contents -->
<details>
  <summary>üóÇÔ∏è Table of Contents</summary>
  <ol>
    <li><a href="#tool-integrated-rl">Tool-Integrated RL</a></li>
    <li><a href="#automatic-searching">Automatic Searching</a></li>
    <li><a href="#rl-for-llms">RL for LLMs</a></li>
  </ol>
</details>

## Tool-Integrated RL

- [ToolRL: Reward is All Tool Learning Needs](https://arxiv.org/abs/2504.13958), arxiv 2504 ![](https://img.shields.io/badge/Method-orange)

- [ReTool: Reinforcement Learning for Strategic Tool Use in LLMs](https://arxiv.org/pdf/2504.11536), arxiv 2504 ![](https://img.shields.io/badge/Method-orange)

- [OTC: Optimal Tool Calls via Reinforcement Learning](https://arxiv.org/pdf/2504.14870), arxiv 2504 ![](https://img.shields.io/badge/Method-orange)

- [ToolRL: Reward is All Tool Learning Needs](https://arxiv.org/pdf/2504.13958), arxiv 2504 [[code](https://github.com/qiancheng0/ToolRL)] ![](https://img.shields.io/badge/Method-orange)

- [ToRL: Scaling Tool-Integrated RL](https://arxiv.org/pdf/2503.23383), arxiv 2503 [[code](https://github.com/GAIR-NLP/ToRL)] ![](https://img.shields.io/badge/Method-orange)

<p align="right" style="font-size: 14px; color: #555; margin-top: 20px;">
    <a href="#readme-top" style="text-decoration: none; color: #007bff; font-weight: bold;">
        ‚Üë Back to Top
    </a>
</p>

## Automatic Searching
- [DeepResearcher: Scaling Deep Research via Reinforcement Learning in Real-world Environments](https://arxiv.org/abs/2504.03160), arxiv 2504 [[code](https://github.com/GAIR-NLP/DeepResearcher)] ![](https://img.shields.io/badge/Method-orange)

- [Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning](https://arxiv.org/pdf/2503.09516), arxiv 2503 [[code](https://github.com/PeterGriffinJin/Search-R1)] ![](https://img.shields.io/badge/Method-orange)

- [ReSearch: Learning to Reason with Search for LLMs via Reinforcement Learning](https://arxiv.org/pdf/2503.19470), arxiv 2503 [[code](https://github.com/Agent-RL/ReCall)] ![](https://img.shields.io/badge/Method-orange)

<p align="right" style="font-size: 14px; color: #555; margin-top: 20px;">
    <a href="#readme-top" style="text-decoration: none; color: #007bff; font-weight: bold;">
        ‚Üë Back to Top
    </a>
</p>

## RL for LLMs
- [TTRL: Test-Time Reinforcement Learning](https://arxiv.org/pdf/2504.16084), arxiv 2504 ![](https://img.shields.io/badge/Method-orange)

    Training LLMs using RL on unlabeled data. 

- [LLMs are Greedy Agents: Effects of RL Fine-tuning on Decision-Making Abilities](https://arxiv.org/pdf/2504.16078), arxiv 2504 ![](https://img.shields.io/badge/Evaluation-green) ![](https://img.shields.io/badge/Method-orange)

    Investigating why LLMs perform sub-optimally in decision-making scenarios: greediness, frequency bias, and the knowing-doing gap. Proposing mitigation by fine-tuning via RL on self-generated CoT rationales.

<p align="right" style="font-size: 14px; color: #555; margin-top: 20px;">
    <a href="#readme-top" style="text-decoration: none; color: #007bff; font-weight: bold;">
        ‚Üë Back to Top
    </a>
</p>
